{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd511de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Census\") \\\n",
    "        .master('local[*]') \\\n",
    "        .enableHiveSupport() \\\n",
    "        .config('spark.drive.host', 'localhost') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e70788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup variables\n",
    "input_data = r\"F:\\DataSamples\\DataExplorer\\Census\\Census_Surnames\\Names_2010Census.csv\"\n",
    "\n",
    "b_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acc2958e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: F:/DataSamples/DataExplorer/Census/Census_Surnames/Names_2010Census.csv\n"
     ]
    }
   ],
   "source": [
    "input_data = input_data.replace('\\\\', '/')\n",
    "print(f\"Input data: {input_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f077a441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "create or replace temporary view census_raw\n",
    "using csv\n",
    "options (\n",
    "    path \"{input_data}\",\n",
    "    inferSchema \"true\",\n",
    "    header \"true\"\n",
    ")\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07aa4ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-------+--------+------------+--------+--------+------+-------+---------+-----------+\n",
      "|     name|rank|  count|prop100k|cum_prop100k|pctwhite|pctblack|pctapi|pctaian|pct2prace|pcthispanic|\n",
      "+---------+----+-------+--------+------------+--------+--------+------+-------+---------+-----------+\n",
      "|    SMITH|   1|2442977|  828.19|      828.19|    70.9|   23.11|   0.5|   0.89|     2.19|        2.4|\n",
      "|  JOHNSON|   2|1932812|  655.24|     1483.42|   58.97|   34.63|  0.54|   0.94|     2.56|       2.36|\n",
      "| WILLIAMS|   3|1625252|  550.97|     2034.39|   45.75|   47.68|  0.46|   0.82|     2.81|       2.49|\n",
      "|    BROWN|   4|1437026|  487.16|     2521.56|   57.95|    35.6|  0.51|   0.87|     2.55|       2.52|\n",
      "|    JONES|   5|1425470|  483.24|      3004.8|   55.19|   38.48|  0.44|      1|     2.61|       2.29|\n",
      "|   GARCIA|   6|1166120|  395.32|     3400.12|    5.38|    0.45|  1.41|   0.47|     0.26|      92.03|\n",
      "|   MILLER|   7|1161437|  393.74|     3793.86|   84.11|   10.76|  0.54|   0.66|     1.77|       2.17|\n",
      "|    DAVIS|   8|1116357|  378.45|     4172.31|    62.2|    31.6|  0.49|   0.82|     2.45|       2.44|\n",
      "|RODRIGUEZ|   9|1094924|  371.19|      4543.5|    4.75|    0.54|  0.57|   0.18|     0.18|      93.77|\n",
      "| MARTINEZ|  10|1060159|   359.4|      4902.9|    5.28|    0.49|   0.6|   0.51|     0.22|      92.91|\n",
      "+---------+----+-------+--------+------------+--------+--------+------+-------+---------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.table(\"census_raw\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46737bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table if exists census\")\n",
    "\n",
    "sql = f\"\"\"\n",
    "create table if not exists census\n",
    "(\n",
    "    name string,\n",
    "    rank int,\n",
    "    count int,\n",
    "    prop100k decimal(12, 5),\n",
    "    cum_prop100k decimal(12, 5),\n",
    "    pctwhite string,\n",
    "    pctblack string,\n",
    "    pctapi string,\n",
    "    pctaian string,\n",
    "    pct2prace string,\n",
    "    pcthispanic string\n",
    ")\n",
    "using csv\n",
    "options (\n",
    "    path \"{input_data}\",\n",
    "    header \"true\"\n",
    ")\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72034237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-------+---------+------------+--------+--------+------+-------+---------+-----------+\n",
      "|     name|rank|  count| prop100k|cum_prop100k|pctwhite|pctblack|pctapi|pctaian|pct2prace|pcthispanic|\n",
      "+---------+----+-------+---------+------------+--------+--------+------+-------+---------+-----------+\n",
      "|    SMITH|   1|2442977|828.19000|   828.19000|    70.9|   23.11|   0.5|   0.89|     2.19|        2.4|\n",
      "|  JOHNSON|   2|1932812|655.24000|  1483.42000|   58.97|   34.63|  0.54|   0.94|     2.56|       2.36|\n",
      "| WILLIAMS|   3|1625252|550.97000|  2034.39000|   45.75|   47.68|  0.46|   0.82|     2.81|       2.49|\n",
      "|    BROWN|   4|1437026|487.16000|  2521.56000|   57.95|    35.6|  0.51|   0.87|     2.55|       2.52|\n",
      "|    JONES|   5|1425470|483.24000|  3004.80000|   55.19|   38.48|  0.44|      1|     2.61|       2.29|\n",
      "|   GARCIA|   6|1166120|395.32000|  3400.12000|    5.38|    0.45|  1.41|   0.47|     0.26|      92.03|\n",
      "|   MILLER|   7|1161437|393.74000|  3793.86000|   84.11|   10.76|  0.54|   0.66|     1.77|       2.17|\n",
      "|    DAVIS|   8|1116357|378.45000|  4172.31000|    62.2|    31.6|  0.49|   0.82|     2.45|       2.44|\n",
      "|RODRIGUEZ|   9|1094924|371.19000|  4543.50000|    4.75|    0.54|  0.57|   0.18|     0.18|      93.77|\n",
      "| MARTINEZ|  10|1060159|359.40000|  4902.90000|    5.28|    0.49|   0.6|   0.51|     0.22|      92.91|\n",
      "+---------+----+-------+---------+------------+--------+--------+------+-------+---------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.table(\"census\")\n",
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3cb062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'parquet'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check current default format\n",
    "spark.conf.get(\"spark.sql.sources.default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e717da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE sales (product STRING, date DATE, amount DECIMAL(10,2))\n",
    "USING PARQUET\n",
    "PARTITIONED BY (date);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ad4cb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"INSERT INTO sales (product, date, amount)  VALUES\n",
    "('Widget', date('2023-01-01'), 19.99), \n",
    "('Gadget', date('2023-01-02'), 29.99),\n",
    "('Widget', date('2023-01-03'), 19.99),\n",
    "('Gadget', date('2023-01-04'), 29.99),\n",
    "('Widget', date('2023-01-05'), 19.99);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d755f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|createtab_stmt                                                                                                                              |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|CREATE TABLE spark_catalog.default.sales (\\n  product STRING,\\n  amount DECIMAL(10,2),\\n  date DATE)\\nUSING PARQUET\\nPARTITIONED BY (date)\\n|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "+---------------+\n",
      "|      partition|\n",
      "+---------------+\n",
      "|date=2023-01-01|\n",
      "|date=2023-01-02|\n",
      "|date=2023-01-03|\n",
      "|date=2023-01-04|\n",
      "|date=2023-01-05|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get table creation statement (shows structure and storage details)\n",
    "spark.sql(\"SHOW CREATE TABLE sales\").show(truncate=False)\n",
    "\n",
    "# For partitioned tables, see partition structure\n",
    "spark.sql(\"SHOW PARTITIONS sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a7dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+------------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                           |comment|\n",
      "+----------------------------+------------------------------------------------------------------------------------+-------+\n",
      "|product                     |string                                                                              |NULL   |\n",
      "|amount                      |decimal(10,2)                                                                       |NULL   |\n",
      "|date                        |date                                                                                |NULL   |\n",
      "|# Partition Information     |                                                                                    |       |\n",
      "|# col_name                  |data_type                                                                           |comment|\n",
      "|date                        |date                                                                                |NULL   |\n",
      "|                            |                                                                                    |       |\n",
      "|# Detailed Table Information|                                                                                    |       |\n",
      "|Catalog                     |spark_catalog                                                                       |       |\n",
      "|Database                    |default                                                                             |       |\n",
      "|Table                       |sales                                                                               |       |\n",
      "|Owner                       |dalej                                                                               |       |\n",
      "|Created Time                |Wed Jul 09 11:34:02 EDT 2025                                                        |       |\n",
      "|Last Access                 |UNKNOWN                                                                             |       |\n",
      "|Created By                  |Spark 3.5.3                                                                         |       |\n",
      "|Type                        |MANAGED                                                                             |       |\n",
      "|Provider                    |PARQUET                                                                             |       |\n",
      "|Location                    |file:/C:/Users/dalej/Documents/_Coding/DataExplorer/CensusData/spark-warehouse/sales|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe                         |       |\n",
      "|InputFormat                 |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat                       |       |\n",
      "+----------------------------+------------------------------------------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_format = spark.sql(\"describe formatted sales\")\n",
    "df_format.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71a5e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------+-----------------------+-----------+---------------+-------------+------------------------------+---------+---------------------------------------------------------------+-----------+--------------------------------------------------------------------------------------+----------------------------------------------------------------+-------+------------------+---------+-------------------------------------------------------------+-------+---------+---------------+------------+--------+\n",
      "|   |# Detailed Table Information|# Partition Information|# col_name |Catalog        |Created By   |Created Time                  |Database |InputFormat                                                    |Last Access|Location                                                                              |OutputFormat                                                    |Owner  |Partition Provider|Provider |Serde Library                                                |Table  |Type     |amount         |date        |product |\n",
      "+---+----------------------------+-----------------------+-----------+---------------+-------------+------------------------------+---------+---------------------------------------------------------------+-----------+--------------------------------------------------------------------------------------+----------------------------------------------------------------+-------+------------------+---------+-------------------------------------------------------------+-------+---------+---------------+------------+--------+\n",
      "|[] |[]                          |[]                     |[data_type]|[spark_catalog]|[Spark 3.5.3]|[Wed Jul 09 11:34:02 EDT 2025]|[default]|[org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat]|[UNKNOWN]  |[file:/C:/Users/dalej/Documents/_Coding/DataExplorer/CensusData/spark-warehouse/sales]|[org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat]|[dalej]|[Catalog]         |[PARQUET]|[org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe]|[sales]|[MANAGED]|[decimal(10,2)]|[date, date]|[string]|\n",
      "+---+----------------------------+-----------------------+-----------+---------------+-------------+------------------------------+---------+---------------------------------------------------------------+-----------+--------------------------------------------------------------------------------------+----------------------------------------------------------------+-------+------------------+---------+-------------------------------------------------------------+-------+---------+---------------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pivot the df_format DataFrame to show data types as columns and their corresponding column names\n",
    "pivot_df = df_format.groupBy().pivot(\"col_name\").agg(expr(\"collect_list(data_type) as columns\"))\n",
    "pivot_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69b733a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------+-----------------------+----------+-------------+-----------+----------------------------+--------+-------------------------------------------------------------+-----------+------------------------------------------------------------------------------------+--------------------------------------------------------------+-----+------------------+--------+-----------------------------------------------------------+-----+-------+-------------+----+-------+\n",
      "|   |# Detailed Table Information|# Partition Information|# col_name|Catalog      |Created By |Created Time                |Database|InputFormat                                                  |Last Access|Location                                                                            |OutputFormat                                                  |Owner|Partition Provider|Provider|Serde Library                                              |Table|Type   |amount       |date|product|\n",
      "+---+----------------------------+-----------------------+----------+-------------+-----------+----------------------------+--------+-------------------------------------------------------------+-----------+------------------------------------------------------------------------------------+--------------------------------------------------------------+-----+------------------+--------+-----------------------------------------------------------+-----+-------+-------------+----+-------+\n",
      "|   |                            |                       |data_type |spark_catalog|Spark 3.5.3|Wed Jul 09 11:34:02 EDT 2025|default |org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat|UNKNOWN    |file:/C:/Users/dalej/Documents/_Coding/DataExplorer/CensusData/spark-warehouse/sales|org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat|dalej|Catalog           |PARQUET |org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe|sales|MANAGED|decimal(10,2)|date|string |\n",
      "+---+----------------------------+-----------------------+----------+-------------+-----------+----------------------------+--------+-------------------------------------------------------------+-----------+------------------------------------------------------------------------------------+--------------------------------------------------------------+-----+------------------+--------+-----------------------------------------------------------+-----+-------+-------------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivot_df = df_format.groupBy().pivot(\"col_name\").agg(expr(\"min(data_type) as columns\"))\n",
    "pivot_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8035cb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "CREATE TABLE employees (\n",
    "    id BIGINT,\n",
    "    name STRING,\n",
    "    salary DECIMAL(10,2),\n",
    "    hire_date DATE,\n",
    "    is_active BOOLEAN,\n",
    "    skills ARRAY<STRING>,\n",
    "    metadata MAP<STRING, STRING>,\n",
    "    address STRUCT<street: STRING, city: STRING, zipcode: STRING>\n",
    ");\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a814003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
