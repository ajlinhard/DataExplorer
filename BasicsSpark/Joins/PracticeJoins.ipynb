{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c77479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PracticeJoins\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.host\", \"localhost\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5519fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data creation\n",
    "customers_data = [\n",
    "    (1, \"John Doe\", \"john@email.com\", \"New York\"),\n",
    "    (2, \"Jane Smith\", \"jane@email.com\", \"California\"),\n",
    "    (3, \"Bob Johnson\", \"bob@email.com\", \"Texas\"),\n",
    "    (4, \"Alice Brown\", \"alice@email.com\", \"Florida\")\n",
    "]\n",
    "\n",
    "orders_data = [\n",
    "    (101, 1, \"2023-01-15\", 250.00, \"completed\"),\n",
    "    (102, 2, \"2023-01-16\", 180.50, \"completed\"),\n",
    "    (103, 1, \"2023-01-17\", 320.75, \"pending\"),\n",
    "    (104, 3, \"2023-01-18\", 95.25, \"completed\"),\n",
    "    (105, 2, \"2023-01-19\", 450.00, \"cancelled\")\n",
    "]\n",
    "\n",
    "order_items_data = [\n",
    "    (1, 101, 201, 2, 50.00),\n",
    "    (2, 101, 202, 1, 150.00),\n",
    "    (3, 102, 201, 3, 50.00),\n",
    "    (4, 102, 203, 1, 30.50),\n",
    "    (5, 103, 202, 2, 150.00),\n",
    "    (6, 103, 204, 1, 20.75),\n",
    "    (7, 104, 201, 1, 50.00),\n",
    "    (8, 104, 205, 2, 22.63),\n",
    "    (9, 105, 202, 3, 150.00)\n",
    "]\n",
    "\n",
    "products_data = [\n",
    "    (201, \"Laptop\", \"Electronics\", 1200.00),\n",
    "    (202, \"Headphones\", \"Electronics\", 150.00),\n",
    "    (203, \"Book\", \"Education\", 30.50),\n",
    "    (204, \"Notebook\", \"Office\", 20.75),\n",
    "    (205, \"Pen\", \"Office\", 22.63)\n",
    "]\n",
    "\n",
    "categories_data = [\n",
    "    (\"Electronics\", \"Tech products and gadgets\"),\n",
    "    (\"Education\", \"Books and learning materials\"),\n",
    "    (\"Office\", \"Office supplies and stationery\")\n",
    "]\n",
    "\n",
    "# Create DataFrames\n",
    "customers = spark.createDataFrame(customers_data, \n",
    "    [\"customer_id\", \"name\", \"email\", \"state\"])\n",
    "\n",
    "orders = spark.createDataFrame(orders_data, \n",
    "    [\"order_id\", \"customer_id\", \"order_date\", \"total_amount\", \"status\"])\n",
    "\n",
    "order_items = spark.createDataFrame(order_items_data, \n",
    "    [\"item_id\", \"order_id\", \"product_id\", \"quantity\", \"unit_price\"])\n",
    "\n",
    "products = spark.createDataFrame(products_data, \n",
    "    [\"product_id\", \"product_name\", \"category\", \"list_price\"])\n",
    "\n",
    "categories = spark.createDataFrame(categories_data, \n",
    "    [\"category_name\", \"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3bc6f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------+----------+--------+----------+------------+---------+\n",
      "|customer_id|name       |email         |state     |order_id|order_date|total_amount|status   |\n",
      "+-----------+-----------+--------------+----------+--------+----------+------------+---------+\n",
      "|1          |John Doe   |john@email.com|New York  |101     |2023-01-15|250.0       |completed|\n",
      "|1          |John Doe   |john@email.com|New York  |103     |2023-01-17|320.75      |pending  |\n",
      "|2          |Jane Smith |jane@email.com|California|102     |2023-01-16|180.5       |completed|\n",
      "|2          |Jane Smith |jane@email.com|California|105     |2023-01-19|450.0       |cancelled|\n",
      "|3          |Bob Johnson|bob@email.com |Texas     |104     |2023-01-18|95.25       |completed|\n",
      "+-----------+-----------+--------------+----------+--------+----------+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_j = customers.join(orders, \"customer_id\", how=\"inner\")\n",
    "df_j.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0b19993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------------+----------+--------+-----------+----------+------------+---------+\n",
      "|customer_id|name       |email          |state     |order_id|customer_id|order_date|total_amount|status   |\n",
      "+-----------+-----------+---------------+----------+--------+-----------+----------+------------+---------+\n",
      "|1          |John Doe   |john@email.com |New York  |103     |1          |2023-01-17|320.75      |pending  |\n",
      "|1          |John Doe   |john@email.com |New York  |101     |1          |2023-01-15|250.0       |completed|\n",
      "|2          |Jane Smith |jane@email.com |California|105     |2          |2023-01-19|450.0       |cancelled|\n",
      "|3          |Bob Johnson|bob@email.com  |Texas     |104     |3          |2023-01-18|95.25       |completed|\n",
      "|4          |Alice Brown|alice@email.com|Florida   |NULL    |NULL       |NULL      |NULL        |NULL     |\n",
      "+-----------+-----------+---------------+----------+--------+-----------+----------+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_j2 = customers.alias(\"c\").join(orders.alias(\"o\"), \n",
    "    (col(\"c.customer_id\") == col(\"o.customer_id\")) & (col(\"o.order_id\") != lit(102)),\n",
    "     how=\"left\")\n",
    "df_j2.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ebc76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+------------+---------+----------------+\n",
      "|order_id|customer_id|order_date|total_amount|status   |random_id       |\n",
      "+--------+-----------+----------+------------+---------+----------------+\n",
      "|101     |1          |2023-01-15|250.0       |completed|[37, 29, 89, 61]|\n",
      "|102     |2          |2023-01-16|180.5       |completed|[12, 76, 37, 24]|\n",
      "|103     |1          |2023-01-17|320.75      |pending  |[50, 99, 56, 16]|\n",
      "|104     |3          |2023-01-18|95.25       |completed|[82, 60, 41, 38]|\n",
      "|105     |2          |2023-01-19|450.0       |cancelled|[96, 9, 27, 99] |\n",
      "+--------+-----------+----------+------------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_int(min_value, max_value, size):\n",
    "    return [random.randint(min_value, max_value) for _ in range(size)]\n",
    "\n",
    "udf_random_int = udf(random_int, ArrayType(IntegerType()))\n",
    "\n",
    "df_order = orders.withColumn(\"random_id\", udf_random_int(lit(1), lit(100), lit(4)))\n",
    "df_order.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1b78b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@udf(IntegerType())\n",
    "def array_sum(arr):\n",
    "    val = 0\n",
    "    for item in arr:\n",
    "        val += item\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed28c6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+------------+---------+----------------+----------+\n",
      "|order_id|customer_id|order_date|total_amount|status   |random_id       |random_sum|\n",
      "+--------+-----------+----------+------------+---------+----------------+----------+\n",
      "|101     |1          |2023-01-15|250.0       |completed|[28, 86, 35, 41]|317       |\n",
      "|102     |2          |2023-01-16|180.5       |completed|[74, 73, 54, 42]|154       |\n",
      "|103     |1          |2023-01-17|320.75      |pending  |[88, 28, 82, 64]|206       |\n",
      "|104     |3          |2023-01-18|95.25       |completed|[1, 32, 28, 74] |124       |\n",
      "|105     |2          |2023-01-19|450.0       |cancelled|[45, 2, 72, 62] |236       |\n",
      "+--------+-----------+----------+------------+---------+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_order.withColumn(\"random_sum\", array_sum(col(\"random_id\"))).show(10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
